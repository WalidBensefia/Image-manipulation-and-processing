# -*- coding: utf-8 -*-
"""Image manipulation and processing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h5S9Q8lunHLbalWx4NloX-pkNIGrHEkt
"""

import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cmath
import os
from google.colab.patches import cv2_imshow
from skimage.color import rgb2gray, gray2rgb

from google.colab import drive
drive.mount('/content/drive')

"""**Manipulation 1**

**1- Creation des Matrices I1, I2, I3:**
"""

A = np.arange(0,256,4)
B= np.array([0,0,0,0,0,0,0,0])
C = np.array([0,0,1,1,1,1,0,0])

I1 = np.tile(A,(64,1))
print(I1)

I2= np.array([B,B,C,C,C,C,B,B])
print(I2)

I33 = np.concatenate((I2,I2), axis = 1)
I3 = np.concatenate((I33,I33), axis = 0)
print(I3)

"""**2-**

2-1/ Convertion des 3 matrices en unit 8:


"""

print("Le type de la matrice I1 avant la convertion :" ,I1.dtype)
print("Le type de la matrice I2 avant la convertion :" ,I2.dtype)
print("Le type de la matrice I3 avant la convertion :" ,I3.dtype)

I1 = np.uint8(I1)
I2 = np.uint8(I2)
I3 = np.uint8(I3)

print("Le type de la matrice I1 aprés la convertion :" ,I1.dtype)
print("Le type de la matrice I2 aprés la convertion :" ,I2.dtype)
print("Le type de la matrice I3 aprés la convertion :" ,I3.dtype)

"""**2-2/ La Visualisation**

**2-2/**

Remarque : la fonction *cv.imshow("Image", nom de la matrice)* ne marche pas sur Google_Collab, du coup on s'est limité à la deuxième méthode !
"""

fig, ax = plt.subplots(nrows=1, ncols=3)
ax[0].set_title("I1")
ax[0].imshow(I1,cmap='gray')

ax[1].set_title("I2")
ax[1].imshow(I2,cmap='gray')

ax[2].set_title("I3")
ax[2].imshow(I3,cmap='gray')

plt.tight_layout()

"""*Commentaire :*
- Cette méthode n’affiche pas la taille réelle de l’image mais elle les
affiche d’une bonne manière de visualisation.
- L’image L1 est dégradé du blanc au noir, on a pu bien le savoir
avant la visualisation car le vecteur A passe du valeur 0 vers 64 avec
un pas de 4.
-L’image L2 qui est une matrice de 0 centré par un carré de 1, le 0
qui est le noir et le 1 qui est un blanc ce qu’on est entrain de voir sur
l’image.
-L’image L3, de même mais avec 4 carré de 1.

**Manipulation 2**

**1/**
"""

path = '/content/drive/MyDrive/images/mandrill.png'
image = cv.imread(path)
image = cv.cvtColor(image, cv.COLOR_BGR2RGB)
plt.imshow(image)

"""**2/**"""

print("La taille de l'image:", '\033[92m', image.shape)
print('\033[30m',"La profendeur de l'image:",'\033[91m',image.dtype)

"""**3/**

Les valeurs de l’image sont de type « uint8 » : les valeurs des pixels varient de 0 à 255

**4/**
"""

r,g,b  = cv.split(image)

plot1 = plt.subplot2grid((5,4), (0,0),colspan = 2, rowspan = 2)
plot1.imshow(r, cmap = 'gray')
plot2 = plt.subplot2grid((5,4), (0,2),colspan = 2, rowspan = 2)
plot2.imshow(g, cmap = 'gray')
plot3 = plt.subplot2grid((5,4), (3,1),colspan = 2, rowspan = 2)
plot3.imshow(b, cmap= 'gray')

plot1.set_title('The Red layer')
plot2.set_title('The Green layer')
plot3.set_title('The Blue layer')

plt.tight_layout()

"""**5/**
On a dans l'image originale les yeux qui sont orange (une
couleur secondaire composée du rouge et du vert) : 
- On visualise dans l’image du canal vert les yeux sont un peu blanc car l’orange est une composition du vert mais pas autant que le rouge.
- On visualise que dans l’image du canal rouge les yeux sont blanc ce qui explique la présence du rouge beaucoup plus.
- On visualise dans l’image du canal bleu les yeux sont noirs ce qui explique l’absence du bleu ( l’orange n’est pas une composition du bleu )


PS : On remarque donc que le blanc est la présence d'une couleur, contrairement au noir !

**6/ les combinaisons des canaux RGB (5)**
"""

fig,ax = plt.subplots(nrows = 2, ncols=3)
for k in range(2):
  for j in range(3):
    ax[k,j].axis('off')

ax[0,0].imshow(cv.merge([r,g,b]))
ax[0,1].imshow(cv.merge([r,b,g]))
ax[0,2].imshow(cv.merge([g,r,b]))
ax[1,0].imshow(cv.merge([g,b,r]))
ax[1,1].imshow(cv.merge([b,g,r]))
ax[1,2].imshow(cv.merge([b,r,g]))

plt.tight_layout()

"""*Commentaire :* 

Lorsqu'on change l'ordre des canaux RGB, les couleurs de l'image changent !

**7/**
"""

cv.imwrite('/content/drive/MyDrive/images/savedImage.png',r)
cv.imwrite('/content/drive/MyDrive/images/savedImage.bmp',g)
cv.imwrite('/content/drive/MyDrive/images/savedImage.jpeg',b)

"""**8/**"""

luminance = 0.2126*r+0.7152*g+0.0722*b
plt.imshow(luminance, cmap = 'gray')

"""**9/**"""

im9 =cv.cvtColor(image, cv.COLOR_BGR2GRAY)
plt.imshow(im9, cmap = 'gray')

im9 == luminance

"""non, on n'obtient pas le meme résultat, il y a une petite différence qui peut etre justifiée par les légères **imprécision** et **incertitude** qu'il y'a dans **la formule** de la *Luminance* de *la question 8*.

**Manipulation 3**

**1/**
"""

path = '/content/drive/MyDrive/images/zelda.png'
zelda = cv.imread(path)
plt.imshow(zelda)

print(zelda.dtype)
print(zelda.shape)

print("la dimension de l'image est : ",zelda.shape)

poids = 135
print("Le poids de l'image est : ", poids, "Ko")

"""**2/ le sous-échantillonnage de l’image**"""

zelda_gray = rgb2gray(zelda)

r,g,b = cv.split(zelda)
r = r[0:512:2, 0:512:2]
g = g[0:512:2, 0:512:2]
b = b[0:512:2, 0:512:2]
zelda_degrade = cv.merge([r,g,b])
plt.imshow(zelda_degrade)

cv.imwrite('/content/drive/MyDrive/images/zelda_degrade.png',zelda_degrade)

"""Le poids de l'image résultante est inférieur au poids de l'image originale

**3/**
"""

zelda_gray = rgb2gray(zelda)

zelda_128 = zelda_gray*128
for i in range(0,512):
  for j in range (0,512):
    zelda_128[i,j] = round(zelda_128[i,j])
  
zelda_64 = zelda_gray*64
for i in range(0,512):
  for j in range (0,512):
    zelda_64[i,j] = round(zelda_64[i,j])

zelda_32 = zelda_gray*32
for i in range(0,512):
  for j in range (0,512):
    zelda_32[i,j] = round(zelda_32[i,j])

zelda_16 = zelda_gray*16
for i in range(0,512):
  for j in range (0,512):
    zelda_16[i,j] = round(zelda_16[i,j])

zelda_8 = zelda_gray*8
for i in range(0,512):
  for j in range (0,512):
    zelda_8[i,j] = round(zelda_8[i,j])

zelda_4 = zelda_gray*4
for i in range(0,512):
  for j in range (0,512):
    zelda_4[i,j] = round(zelda_4[i,j])

zelda_2 = zelda_gray*2
for i in range(0,512):
  for j in range (0,512):
    zelda_2[i,j] = round(zelda_2[i,j])

"""**4/**"""

fig, ax = plt.subplots(2,4)
ax[0,0].imshow(zelda_gray, cmap = 'gray')
ax[0,1].imshow(zelda_128, cmap = 'gray')
ax[0,2].imshow(zelda_64, cmap = 'gray')
ax[0,3].imshow(zelda_32, cmap = 'gray')
ax[1,0].imshow(zelda_16, cmap = 'gray')
ax[1,1].imshow(zelda_8, cmap = 'gray')
ax[1,2].imshow(zelda_4, cmap = 'gray')
ax[1,3].imshow(zelda_2, cmap = 'gray')

for k in range(2):
  for j in range(4):
    ax[k,j].axis('off')

ax[0,0].set_title("256")
ax[0,1].set_title("128")
ax[0,2].set_title("64")
ax[0,3].set_title("32")
ax[1,0].set_title("16")
ax[1,1].set_title("8")
ax[1,2].set_title("4")
ax[1,3].set_title("2")

plt.tight_layout()

"""le seuil minimal de quantification est 16

**5/**
"""

cv.imwrite('/content/drive/MyDrive/images/zelda_quantifie.png', zelda_16)

"""le taux de rédcution du poids est : ( poids(zelda_gray) - poids(zelda_16) ) / poids(zelda_gray) = 135-50 / 135 = 63 %

**Manipulation 4**

**1/**
"""

path = '/content/drive/MyDrive/images/flower.bmp'
flower = cv.imread(path)
plt.imshow(flower)

"""**2/**"""

b,v,r = cv.split(flower)         
y = 0.299*r + 0.587*v + 0.114*b 
y = y.astype(np.uint8)          
plt.imshow(y,cmap='gray')

flower_gray = cv.cvtColor(flower  , cv.COLOR_BGR2GRAY)
plt.imshow(flower_gray, cmap='gray')

"""**3/**

**3-1/ l'histogramme**
"""

histo = np.zeros(256, int)      
for i in range(0,flower.shape[0]):       
    for j in range(0,flower.shape[1]):   
        histo[y[i,j]] = histo[y[i,j]] + 1
print(histo)
plt.plot(histo)
plt.show()

flower_hist = flower_gray.ravel()
plt.hist(flower_hist, bins = 256, color = 'red')

"""**3-2/ l'histogramme normalisé**"""

plt.hist(flower_gray.ravel(), bins = 256, density = True, color = 'green')

"""*Commentaire :*
- L’histogramme nous donne le nombre d’apparition de niveau de gris.
- L’histogramme normalisé nous donne la probabilité d’occurrence de
niveau de gris (la fréquence d’apparition)

**4/ l'histogramme cumulé**
"""

plt.hist(flower_gray.ravel(), bins = 256, density = True,cumulative=True, color = '#DE6564')

"""*Commentaire :*

L’histogramme cumulé nous donne le taux d'apparition de tous les
niveaux de gris inférieurs à une certaine valeur.

**5/ l'égalisation d'histogramme**
"""

def image_egalisation(image):
  img = np.asarray(image)
  flat = img.ravel()
  histogram = np.zeros(256)
  for pixel in flat:
    histogram[pixel] += 1
  histogram = iter(histogram)
  b = [next(histogram)]
  for i in histogram:
    b.append(b[-1] + i)
  cs = np.array(b)
  nj = (cs - cs.min()) * 255
  N = cs.max() - cs.min()
  cs = cs.astype('uint8')
  cs = nj / N
  img_new = cs[flat]
  img_new = np.reshape(img_new, image.shape)
  return img_new

leg_im = image_egalisation(flower_gray)

"""*Commentaire :*

Après avoir égaliser l'histogramme, le contraste de l'image a augmenté.

**6/**

Remarque : la method *cv.equalizeHist* ne marche pas sur Google_Collab, du coup on a utilisé la method *skimage.exposure.equalize_hist* !
"""

from skimage import exposure
equalized_image = exposure.equalize_hist(flower_gray)

fig, axis = plt.subplots(nrows = 2, ncols = 3)
axis[0,0].imshow(flower_gray, cmap = 'gray')
axis[0,1].imshow(leg_im, cmap = 'gray')
axis[0,2].imshow(equalized_image, cmap = 'gray')

axis[0,0].set_title('Original')
axis[0,1].set_title('Equilized ')
axis[0,2].set_title('Equilized using\n "equalize_hist"')

axis[1,0].hist(flower_gray.ravel(), bins = 256, density = True)
axis[1,1].hist(leg_im.ravel(), bins = 256, density = True, color = 'red') 
axis[1,2].hist(equalized_image.ravel(), bins = 256, density = True, color = 'green') 

for j in range(3):
  axis[0,j].axis('off')

plt.tight_layout()

fig, ax = plt.subplots(nrows = 1, ncols= 2)
ax[0].imshow(leg_im, cmap = 'gray')
ax[1].imshow(equalized_image, cmap = 'gray')

plt.tight_layout()

"""**7/**"""

from skimage.color import rgb2gray
r_fl,g_fl,b_fl  = cv.split(flower)
r_eg_fl = exposure.equalize_hist(r_fl)
g_eg_fl = exposure.equalize_hist(g_fl)
b_eg_fl = exposure.equalize_hist(b_fl)
image = cv.merge([r_eg_fl, g_eg_fl, b_eg_fl])
plt.imshow(image)

import skimage.measure as skm    
entropy = skm.shannon_entropy(image)
print('l\'entropy : ', entropy)

"""**8/**"""

ycrcb = cv.cvtColor(flower, cv.COLOR_BGR2YCrCb)
y,cr,cb = cv.split(ycrcb)
y = exposure.equalize_hist(y)
ycrcb_egl = cv.merge([y,cr,cb])
equalized_img = cv.cvtColor(ycrcb_egl, cv.COLOR_YCrCb2BGR)
plt.imshow(equalized_image)

import skimage.measure as skm    
entropy = skm.shannon_entropy(equalized_img)
print('l\'entropy de l\'image égalisé par rapport à l’histogramme cumulé: ', entropy)

"""**9/**

*Commentaire et comparaison :*

on voit que l'égalisation par rapport a l’histogramme cumulé donne de meilleurs resultas que celle obtenu en égalisant chaque canal indépendamment, mais l'entropie a été diminue plus.
Ainsi avec l'égalisation par rapport a l’histogramme cumulé l’image a été améliorée le mieux,mais l’information contenue dans l’image a diminué  ce qui s'explique par l'apparition de trous dans son histogramme.

**10/**
"""

path = '/content/drive/MyDrive/images/pentagon.tif'
pentagon = cv.imread(path)
plt.imshow(pentagon)

r_pen,g_pen,b_pen  = cv.split(pentagon)
r_eg_pen = exposure.equalize_hist(r)
g_eg_pen = exposure.equalize_hist(g)
b_eg_pen = exposure.equalize_hist(b)
image = cv.merge([r_eg_pen, g_eg_pen, b_eg_pen])
plt.imshow(image)

"""*Commentaire :*

Après l’égalisation, le contraste est plus défini et ajusté ! 

Ce qui rend l’image plus claire

**11/**
"""

from skimage.exposure import match_histograms
image = cv.imread('/content/drive/MyDrive/images/cameraman.jpg')
reference = cv.imread('/content/drive/MyDrive/images/barbara.png')
matched = match_histograms(image, reference, multichannel=True)

fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),
                                    sharex=True, sharey=True)
for aa in (ax1, ax2, ax3):
    aa.set_axis_off()

ax1.imshow(image)
ax1.set_title('Source')
ax2.imshow(reference)
ax2.set_title('Reference')
ax3.imshow(matched)
ax3.set_title('Matched')

plt.tight_layout()
plt.show()